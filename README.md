# lab6
Лабораторная работа №6 - Алгоритмы сортировки. Сложность от O(N) до O(N^2)

Итак, мои юные постигатели алгоритмов и структур данных, мы уже более менее освоились с основами программирования, научились работать с памятью, поняли, что такое указатели (и почему они вызывают у вас (да и у меня) холодный пот по ночам). Теперь пришло время поговорить о том, что лежит в основе практически любого алгоритма обработки данных — о сортировке! Да-да, той самой сортировке, без которой мы бы до сих пор искали нужные файлы вручную, как в древних архивах.

Сортировки — это та тема, где теория и практика встречаются лицом к лицу. Вы можете знать все формулы асимптотической сложности, но пока не напишете пузырьковую сортировку собственными руками, вы не поймёте, почему она так ненавистна программистам. "Слона надо есть по котлеткам", как говорил один мудрый человек, который явно пытался отсортировать массив из миллиарда элементов на Pentium II.

## Зачем вообще сортировать?
```c
// Пример того, как не надо делать (но мы сначала так и сделаем)
for (int i = 0; i < n; i++) {
    for (int j = 0; j < n - i - 1; j++) {
        if (arr[j] > arr[j+1]) {
            // меняем местами
            int temp = arr[j];
            arr[j] = arr[j+1];
            arr[j+1] = temp;
        }
    }
}
```

Это, друзья мои, знаменитая (или печально известная) "пузырьковая сортировка". Она прекрасна своей простотой, но ужасна своей производительностью. Для массива из 1000 элементов она будет работать... ну, достаточно долго, чтобы вы успели сварить кофе, допить его и начать скучать.

# Практическое задание: погружение в мир сортировок

Итак, хватит теории. В этой лабораторной работе вы не просто скопируете алгоритмы из GPT (хотя я знаю, что вы так хотели сделать). Вы напишете их сами (пожалуйста), измерите их производительность и поймёте, почему O(N²) иногда хуже, чем кажется в учебнике.

## Базовый уровень

### Шаг 1: Создание "плохой" сортировки O(N²)

Начнем с простого. Напишите сортировку с квадратичной сложностью. Это может быть:
- Пузырьковая сортировка (bubble sort)
- Сортировка выбором (selection sort)
- Сортировка вставками (insertion sort)


```c
void bubbleSort(int* arr, size_t n) {
    // Ваш код здесь
}
```

### Шаг 2: Создание "хорошей" сортировки O(N log N)

Теперь напишите сортировку со средней сложностью O(N log N). Варианты:
- Быстрая сортировка (quicksort)
- Сортировка слиянием (mergesort)
- Пирамидальная сортировка (heapsort)

```c
void quickSort(int* arr, int low, int high) {
    // Ваш код здесь
    // Подсказка: разделение на части и рекурсия
    // И да, не забудьте про базовый случай, иначе стек переполнится
}
```

### Шаг 3: Создание "волшебной" сортировки O(N)

Для этой части вам понадобится линейная сортировка. Это может быть:
- Сортировка подсчетом (counting sort)
- Поразрядная сортировка (radix sort)
- Блочная сортировка (bucket sort)

Внимание! Эти сортировки работают только для определенных типов данных. Например, сортировка подсчетом отлично работает для целых чисел в ограниченном диапазоне.

```c
void countingSort(int* arr, size_t n, int max_value) {
    // Ваш код здесь
    // Подсказка: вам понадобится дополнительный массив размером max_value
}
```

### Шаг 4: Генерация случайных данных

Теперь, когда у нас есть сортировки, нужно научиться генерировать случайные массивы для тестирования:

```c
int* createRandomArray(size_t size) {
    srand(time(NULL));  // Инициализация генератора случайных чисел
    
    int* array = (int*)malloc(size * sizeof(int));
    if (!array) {
        perror("Memory allocation failed");
        exit(EXIT_FAILURE);
    }
    
    for (size_t i = 0; i < size; i++) {
        array[i] = rand();  // Случайные числа от 0 до RAND_MAX
    }
    
    return array;
}
```

### Шаг 5: Измерение времени выполнения
Ну это всё пример, конечно же  

```c
double measureSortTime(void (*sortFunc)(int*, size_t), size_t arraySize, int iterations) {
    double totalTime = 0.0;
    
    for (int i = 0; i < iterations; i++) {
        int* array = createRandomArray(arraySize);
        
        clock_t start = clock();
        sortFunc(array, arraySize);
        clock_t end = clock();
        
        double timeMs = (double)(end - start) / CLOCKS_PER_SEC * 1000.0;
        totalTime += timeMs;
        
        free(array);
        printf("Iteration %d/%d: %.3f ms\n", i+1, iterations, timeMs);
    }
    
    return totalTime / iterations;  // Среднее время
}
```

## Проведение экспериментов

Запустите все три сортировки для разных размеров массивов:

* Для массивов размером 1 000 элементов (100 повторений)
* Для массивов размером 10 000 элементов (100 повторений)
* Для массивов размером 100 000 элементов (100 повторений)
* Для массивов размером 1 000 000 элементов (100 повторений)

## Построение графиков

Возьмите данные из файлов и постройте boxplot-ы.

Например, это можно сделать так:  

```python
import matplotlib.pyplot as plt
import numpy as np

bubble_1000 = np.loadtxt('bubble_sort_1000.txt')
quick_1000 = np.loadtxt('quick_sort_1000.txt')
counting_1000 = np.loadtxt('counting_sort_1000.txt')

fig, ax = plt.subplots()
ax.set_title('Сравнение сортировок для N=1000')
ax.set_ylabel('Время выполнения (мс)')
ax.boxplot([bubble_1000, quick_1000, counting_1000], 
           labels=['Пузырьковая', 'Быстрая', 'Подсчетом'],
           patch_artist=True)

colors = ['lightblue', 'lightgreen', 'lightcoral']
for patch, color in zip(ax.artists, colors):
    patch.set_facecolor(color)

plt.savefig('sorting_comparison_1000.png')
plt.show()
```

Поверьте, когда вы увидите, как пузырьковая сортировка для миллиона элементов работает дольше, чем вы читаете этот текст, вы оцените всю мощь алгоритмов с хорошей асимптотикой )

## Продвинутый уровень (дополнительные баллы)


Сравните ваши реализации сортировок со встроенными в языки программирования:

- C++: `std::sort`, `std::stable_sort`
- Python: `sorted()`, `list.sort()`, `pandas.sort_values()` с разными алгоритмами

Для этого создайте аналогичные тесты и замерьте время выполнения. Скорее всего, вы обнаружите, что стандартные библиотеки оптимизированы лучше, чем ваши первые попытки (ничего личного, так всегда было и будет).

Пример:   
```cpp
#include <algorithm>
#include <vector>

void stdSort(int* arr, size_t n) {
    std::vector<int> vec(arr, arr + n);
    std::sort(vec.begin(), vec.end());
    // Копируем обратно в массив
    std::copy(vec.begin(), vec.end(), arr);
}
```

### Анализ производительности

Постройте графики зависимости времени выполнения от размера массива для всех сортировок. Это поможет вам визуально оценить, насколько теоретическая асимптотическая сложность соответствует реальности.

### Отчет по результатам

В отчете должны быть:
- Графики со сравнением всех сортировок
- Таблицы со средним временем выполнения
- Выводы о том, при каких размерах данных начинает проявляться разница между O(N²) и O(N log N)
- Анализ случаев, когда линейная сортировка действительно работает быстрее
- Сравнение ваших реализаций со стандартными библиотеками

Но без воды, пожалуйста! Не пишите "быстрая сортировка быстрая, потому что она быстрая". Пишите конкретику: "сортировка подсчетом для N=1000000 работает в 3 раза быстрее быстрой сортировки, потому что..."

# Сводка команд для компиляции и запуска

```shell
# Компиляция основной программы
gcc -Wall -Wextra -std=c11 -o sorting_lab sorting_lab.c -lm

# Запуск с параметрами (размер массива, количество итераций)
./sorting_lab 1000 100

# Генерация данных для всех размеров
./sorting_lab 1000 100 && ./sorting_lab 10000 100 && ./sorting_lab 100000 100 && ./sorting_lab 1000000 100

# Запуск Python-скрипта для визуализации
python3 visualize_results.py
```


P.S. И да, я знаю, что вы уже открыли Stack Overflow/GPT/Qwen/<LLM name no matter which one>, чтобы скопировать готовую реализацию быстрой сортировки.  
Но прошу вас - напишите её сами. Поверьте, это того стоит. Когда через 5 лет вас спросят на собеседовании "Расскажите, как работает быстрая сортировка?", вы как минимум шутканёте как вы страдали на алгосах в ИТМО и как у вас это отпечаталось в памяти

